{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\leadw\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.23.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\leadw\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\leadw\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\leadw\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\leadw\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests) (3.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.3.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n",
      "ERROR: Invalid requirement: '#beautifulsoup4'\n",
      "WARNING: You are using pip version 19.3.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\leadw\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\leadw\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from selenium) (1.25.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.3.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install requests\n",
    "!pip3 install bs4 #beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.yes24.com/Product/Goods/7'\n",
    "req = requests.get(url)\n",
    "req.status_code\n",
    "html = req.text\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "a = soup.find(class_= 'gd_name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기억의 상처\n",
      "우동 한그릇\n",
      "큰 오빠 1\n",
      "성공하는 가족들의 7가지 습관\n",
      "주식투자, 제대로 알고하면 진짜 돈된다\n",
      "돈을 끌어오는 마음의 법칙\n",
      "링 3\n",
      "피리새는 피리가 없다 2\n",
      "행복\n",
      "마지막 춤은 나와 함께\n",
      "나를 사랑한 폐인\n",
      "아내 1\n",
      "한국 현대사의 재인식 3\n",
      "텔레비전에 대하여\n",
      "프랑스의 실업자 운동\n",
      "대학의 역사\n",
      "지구촌 시대 21가지 변화와 대응\n",
      "재수가 붙는다 돈이 붙는다\n",
      "경쟁의 종말\n",
      "무지개와 프리즘\n",
      "특명! 나쁜 아이들의 아시아 횡단\n",
      "스핑크스의 코\n",
      "내 무덤에 침을 뱉어라 1\n",
      "산은 산 물은 물 2\n",
      "빈들에서 1\n",
      "우리는 지난 100년동안 어떻게 살았을까 1\n",
      "한국 애니메이션은 없다\n",
      "신라 과학기술의 비밀\n",
      "처음의 마음으로 돌아가라\n",
      "인간은 환경에 어떻게 적응하는가\n",
      "숲을 그리는 마음\n",
      "용의 신전 1\n",
      "말 탄 자는 지나가다\n",
      "불멸 2\n",
      "조선후기 학계와 지식인\n",
      "공공저널리즘과 한국언론 : 언론과 공동체의 새로운 관계 모색\n",
      "인간은 얼마만큼의 진실을 필요로 하는가\n",
      "위기, 그리고 대전환\n",
      "핵무기 없는 세계\n",
      "신화의 세계\n",
      "제2차 세계 대공황이 온다\n",
      "전혜린\n",
      "레오나르도 다 빈치와 마키아벨리\n",
      "칼릴라와 딤나\n",
      "정주영의 성공 손자병법\n",
      "명창 임방울\n",
      "사랑을 읽는다\n",
      "신경림의 시인을 찾아서 1\n",
      "조선의 성풍속\n",
      "헤로도토스의 이집트 기행\n",
      "사랑의 첫 느낌\n",
      "나는 없다\n",
      "삶은 사는 것만큼 행복하고 아름답다\n",
      "그들의 나라 1\n",
      "한눈팔기\n",
      "절벽\n",
      "한국유학사 1\n",
      "조선왕조사 1\n",
      "사죄와 망언 사이에서\n",
      "중국 정치 사상사\n",
      "1950년대 남북한의 선택과 굴절\n",
      "국제커뮤니케이션과 세계화\n",
      "제2미디어 시대\n",
      "한국경제의 펀더멘탈은 튼튼하다\n",
      "사이언스 오딧세이\n",
      "나도 너에게 자유를 주고 싶다\n",
      "모리의 마지막 수업\n",
      "영어, 이렇게 배워야 통한다\n",
      "사랑의 신비\n",
      "레오나르도 다빈치\n",
      "나의 북한 문화유산답사기 (상)\n",
      "터무니 없는 한국사람 얄미운 일본사람\n",
      "인물로 읽는 사기 1\n",
      "20세기 추상미술의 역사\n",
      "금강산 그 든든한 힘\n",
      "공무원은 상전이 아니다\n",
      "사진가와의 대화 1\n",
      "한국역사인물사전\n",
      "한눈으로 보는 한국의 새\n",
      "고구려 역사유적 답사\n",
      "오이디푸스의 결혼\n",
      "메두사\n",
      "가련한 여인의 초상\n",
      "짧은 글 긴 침묵\n",
      "내 마음의 망명정부\n",
      "후투티가 오지 않는 섬\n",
      "일본의 국가전략\n",
      "통일을 위해 남한도 변해야 한다\n",
      "금오신화\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pageNo = 1\n",
    "title = []\n",
    "for i in range(90000000,90020000): \n",
    "    \n",
    "    pageNo = pageNo + 1\n",
    "    url = 'http://www.yes24.com/Product/Goods/{}'.format(pageNo)\n",
    "    req = requests.get(url)\n",
    "    html = req.text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    name = soup.find(class_=\"gd_name\")\n",
    "    if name: title.append(name.text)\n",
    "for j in title :\n",
    "    if j: print(j)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = pd.DataFrame(title)\n",
    "titles.to_csv(\"./titles.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'pandas._libs.tslibs.conversion._TSObject' has no attribute '__reduce_cython__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-e6c0fd289830>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpageNo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mstory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100000000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\leadw\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhashtable\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_hashtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtslib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_tslib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# hack but overkill to use re\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\leadw\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\_libs\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# flake8: noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m from .tslibs import (\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mNaT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mNaTType\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\leadw\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\_libs\\tslibs\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# flake8: noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mconversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlocalize_pydatetime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize_date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mnattype\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNaT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNaTType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miNaT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_null_datetimelike\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mnp_datetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOutOfBoundsDatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36minit pandas._libs.tslibs.conversion\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'pandas._libs.tslibs.conversion._TSObject' has no attribute '__reduce_cython__'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pageNo = 1\n",
    "story = []\n",
    "for i in range(0,100000000): \n",
    "    \n",
    "    pageNo = pageNo + 1\n",
    "    url = 'http://www.yes24.com/Product/Goods/{}'.format(pageNo)\n",
    "    req = requests.get(url)\n",
    "    html = req.text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    name = soup.find(class_=\"infoWrap_txtInner\")\n",
    "    if name: story.append(name.text)\n",
    "for j in story :\n",
    "    if j: print(j)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = pd.DataFrame(story)\n",
    "stories.to_csv(\"./stories.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'pandas._libs.tslibs.conversion._TSObject' has no attribute '__reduce_cython__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-ec40f885e782>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpageNo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mauthor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\leadw\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhashtable\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_hashtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtslib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_tslib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# hack but overkill to use re\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\leadw\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\_libs\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# flake8: noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m from .tslibs import (\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mNaT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mNaTType\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\leadw\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\_libs\\tslibs\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# flake8: noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mconversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlocalize_pydatetime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize_date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mnattype\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNaT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNaTType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miNaT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_null_datetimelike\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mnp_datetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOutOfBoundsDatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36minit pandas._libs.tslibs.conversion\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'pandas._libs.tslibs.conversion._TSObject' has no attribute '__reduce_cython__'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pageNo = 1\n",
    "author = []\n",
    "for i in range(0,10000): \n",
    "    \n",
    "    pageNo = pageNo + 1\n",
    "    url = 'http://www.yes24.com/Product/Goods/{}'.format(pageNo)\n",
    "    req = requests.get(url)\n",
    "    html = req.text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    name = soup.find(class_=\"gd_auth\")\n",
    "    if name: author.append(name.text)\n",
    "for j in author :\n",
    "    if j: print(j)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = pd.DataFrame(author)\n",
    "authors.to_csv(\"./authors.csv\", header = False, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
